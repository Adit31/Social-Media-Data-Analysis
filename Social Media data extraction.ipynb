{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter\n",
    "from tweepy import OAuthHandler, Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import tweepy\n",
    "\n",
    "#YouTube\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "#Instagram\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#Tumblr\n",
    "import pytumblr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "from decouple import Config, RepositoryEnv\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOTENV_FILE = '.env'\n",
    "env_config = Config(RepositoryEnv(DOTENV_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_fetch():\n",
    "    Twitter_ACCESS_TOKEN = env_config.get('Twitter_ACCESS_TOKEN')\n",
    "    Twitter_ACCESS_SECRET = env_config.get('Twitter_ACCESS_SECRET')\n",
    "    Twitter_CONSUMER_KEY = env_config.get('Twitter_CONSUMER_KEY')\n",
    "    Twitter_CONSUMER_SECRET = env_config.get('Twitter_CONSUMER_SECRET')\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(Twitter_CONSUMER_KEY, Twitter_CONSUMER_SECRET)\n",
    "    auth.set_access_token(Twitter_ACCESS_TOKEN, Twitter_ACCESS_SECRET)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "    \n",
    "    for status in tweepy.Cursor(api.home_timeline).items(275):\n",
    "        print(status._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_fetch(channelId):\n",
    "    youTubeApiKey = env_config.get('youTubeApiKey')\n",
    "    youTubeFileLocation = env_config.get('youTubeFileLocation')\n",
    "    youtube = build('youtube','v3',developerKey=youTubeApiKey)\n",
    "    youtubeURL = env_config.get('youtubeURL')\n",
    "    \n",
    "    statdata=youtube.channels().list(part='statistics',id=channelId).execute()\n",
    "    contentdata=youtube.channels().list(id=channelId,part='contentDetails').execute()\n",
    "    playlist_id = contentdata['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    videos = [ ]\n",
    "    next_page_token = None\n",
    "    while 1:\n",
    "        res = youtube.playlistItems().list(playlistId=playlist_id, part='snippet', maxResults=50, pageToken=next_page_token).execute()\n",
    "        videos += res['items']\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "        \n",
    "    video_ids = list(map(lambda x:x['snippet']['resourceId']['videoId'], videos))\n",
    "    stats = []\n",
    "    for i in range(0, len(video_ids),40):\n",
    "        res = (youtube).videos().list(id=','.join(video_ids[i:i+40]),part='statistics').execute()\n",
    "        stats += res['items']\n",
    "   \n",
    "    title=[ ]\n",
    "    liked=[ ]\n",
    "    disliked=[ ]\n",
    "    views=[ ]\n",
    "    url=[ ]\n",
    "    comment=[ ]\n",
    "\n",
    "    for i in range(len(videos)):\n",
    "        title.append((videos[i])['snippet']['title'])\n",
    "        url.append(youtubeURL + (videos[i])['snippet']['resourceId']['videoId'])\n",
    "        liked.append(int((stats[i])['statistics']['likeCount']))\n",
    "        disliked.append(int((stats[i])['statistics']['dislikeCount']))\n",
    "        views.append(int((stats[i])['statistics']['viewCount']))\n",
    "        if 'commentCount' not in (stats[i])[\"statistics\"]:\n",
    "            comment.append(0)\n",
    "        else:\n",
    "            comment.append(int((stats[i])['statistics']['commentCount']))\n",
    "    \n",
    "    data={'title':title,'url':url,'liked':liked,'disliked':disliked,'views':views,'comment':comment}\n",
    "    df=pd.DataFrame(data)\n",
    "    df.to_csv(youTubeFileLocation, header = False, mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instagram_fetch(hashtag_list):\n",
    "    chromeDriverLocation = env_config.get('chromeDriverLocation')\n",
    "    browser = webdriver.Chrome(chromeDriverLocation)\n",
    "    \n",
    "    instagramFileLocation = env_config.get('instagramFileLocation')\n",
    "    instagramTagURL = env_config.get('instagramTagURL')\n",
    "    instagramURL = env_config.get('instagramURL')\n",
    "    \n",
    "    for hashtag in hashtag_list:\n",
    "        browser.get(instagramTagURL + hashtag)\n",
    "        Pagelength = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        links=[]\n",
    "        source = browser.page_source\n",
    "        data=bs(source, 'html.parser')\n",
    "        body = data.find('body')\n",
    "        script = body.find('script', text=lambda t: t.startswith('window._sharedData'))\n",
    "        links=[]\n",
    "        source = browser.page_source\n",
    "        data=bs(source, 'html.parser')\n",
    "        body = data.find('body')\n",
    "        script = body.find('script', text=lambda t: t.startswith('window._sharedData'))\n",
    "        page_json = script.string.split(' = ', 1)[1].rstrip(';')\n",
    "        data = json.loads(page_json)\n",
    "        for link in data['entry_data']['TagPage'][0]['graphql']['hashtag']['edge_hashtag_to_media']['edges']:\n",
    "            links.append(instagramURL + link['node']['shortcode']+'/')\n",
    "        result=pd.DataFrame()\n",
    "        for i in range(len(links)):\n",
    "            try:\n",
    "                page = urlopen(links[i]).read()\n",
    "                data=bs(page, 'html.parser')\n",
    "                body = data.find('body')\n",
    "                script = body.find('script')\n",
    "                raw = script.string.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "                json_data=json.loads(raw)\n",
    "                posts =json_data['entry_data']['PostPage'][0]['graphql']\n",
    "                posts= json.dumps(posts)\n",
    "                posts = json.loads(posts)\n",
    "                x = pd.DataFrame.from_dict(json_normalize(posts), orient='columns') \n",
    "                x.columns = x.columns.str.replace(\"shortcode_media.\", \"\")\n",
    "                result = result.append(x)\n",
    "            except:\n",
    "                np.nan\n",
    "        result = result.drop_duplicates(subset = 'shortcode')\n",
    "        result.index = range(len(result.index))\n",
    "        result.to_csv(instagramFileLocation, mode = 'a', header = False)\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tumblr_fetch(tagList):\n",
    "    Tumblr_API_KEY = env_config.get('Tumblr_API_KEY')\n",
    "    tumblrFileLocation = env_config.get('tumblrFileLocation')\n",
    "    client = pytumblr.TumblrRestClient(Tumblr_API_KEY)\n",
    "    for tag in tagList:\n",
    "        tagdata_json = client.tagged(tag, limit = 200)\n",
    "        tumblr_df = pd.DataFrame.from_dict(json_normalize(tagdata_json), orient='columns') \n",
    "        tumblr_df.to_csv(tumblrFileLocation , mode = 'a', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FetchHashtag():\n",
    "    chromeDriverLocation = env_config.get('chromeDriverLocation')\n",
    "    browser = webdriver.Chrome(chromeDriverLocation)\n",
    "\n",
    "    googleURL = env_config.get('googleURL')\n",
    "    browser.get(googleURL)\n",
    "    search_query = browser.find_element_by_name('q')\n",
    "\n",
    "    search_query.send_keys('popular hashtags')\n",
    "    search_query.send_keys(Keys.ENTER)\n",
    "\n",
    "    urls = browser.find_elements_by_tag_name('a')\n",
    "    for i in urls:\n",
    "        if i.get_attribute('href'):\n",
    "            if 'google' in i.get_attribute('href'):\n",
    "                continue\n",
    "            else:\n",
    "                url = i.get_attribute('href')\n",
    "                break\n",
    "    browser.quit()\n",
    "\n",
    "    resp=requests.get(url)  \n",
    "    soup=bs(resp.text,'html.parser')\n",
    "    hashtag_list = []\n",
    "    for li in soup.findAll(\"ul\"):\n",
    "        for i in li.findAll(\"p\"):\n",
    "            if i.string:\n",
    "                if '#' in i.string:\n",
    "                    hashtag_list.append(i.string.replace('#',''))\n",
    "    instagram_fetch(hashtag_list)\n",
    "    tumblr_fetch(hashtag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input(\"Which platform do you want to use? \\n1. Instagram\\n2. Twitter\\n3. Youtube\\n4. Tumblr\\n\")\n",
    "if x == \"1\":\n",
    "    FetchHashtag()\n",
    "elif x == \"2\":\n",
    "    twitter_fetch()\n",
    "elif x == \"3\":\n",
    "    channelId = input(\"Enter channel Id whose data you want to fetch : \")\n",
    "    youtube_fetch(channelId)\n",
    "elif x == \"4\":\n",
    "    FetchHashtag()\n",
    "else:\n",
    "    print(\"Wrong Value Entered, try again!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
